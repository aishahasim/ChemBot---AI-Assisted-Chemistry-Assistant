from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.schema import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter

splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
chunks = []
for txt in all_texts:
    for chunk in splitter.split_text(txt):
        chunks.append(Document(page_content=chunk))

embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

db = FAISS.from_documents(chunks, embeddings)
docs = db.similarity_search("low-cost materials used as HER catalysts", k=2)
for d in docs:
    print(d.page_content[:500])


